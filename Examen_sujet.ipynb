{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5a75PwbNOxFi"
   },
   "source": [
    "# Importation de SPARK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hst3gL2W5sTl"
   },
   "outputs": [],
   "source": [
    "# import findspark\n",
    "# findspark.init()\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"Python Spark\").getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "\n",
    "sc.setSystemProperty('spark.executor.memory', '8g')\n",
    "sc.setSystemProperty('spark.driver.memory', '45G')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hDGoeoteNwsn"
   },
   "source": [
    "# Sujet\n",
    "On souhaite faire de la segmentation d'utilisateurs. Pour cela, nous allons procéder en deux étapes :\n",
    "\n",
    "* Construction d'un profil utilisateur\n",
    "* Utilisation d'un algorithme de clustering afin de calculer les groupes\n",
    "\n",
    "Le profil d'un utilisateur est composé de 3 dimensions :\n",
    "* le nombre de films d'action\n",
    "* le nombre de films d'aventure\n",
    "* et le nombre de films d'animation\n",
    "\n",
    "Une fois ces quantités calculées, proposez un pipeline qui devra notamment :\n",
    "* normaliser les vecteurs,\n",
    "* et calculer les groupes (clustering)\n",
    "\n",
    "Enfin, les utilisateurs 23 et 49 sont-ils dans le meme groupe ? La réponse doit être la requête que vous proposez ainsi que son résultat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pwr2cD2IO4Xb"
   },
   "outputs": [],
   "source": [
    "df_ratings = spark.read\\\n",
    "    .option(\"delimiter\", \"\\t\")\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .option(\"inferSchema\", \"true\")\\\n",
    "    .csv('data/u.data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user_id: integer (nullable = true)\n",
      " |-- item_id: integer (nullable = true)\n",
      " |-- rating: integer (nullable = true)\n",
      " |-- timestamp: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_ratings.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_items = spark.read\\\n",
    "    .option(\"delimiter\", \"|\")\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .option(\"inferSchema\", \"true\")\\\n",
    "    .csv('data/u.item')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- movie_id: integer (nullable = true)\n",
      " |-- movie_title: string (nullable = true)\n",
      " |-- release_date: string (nullable = true)\n",
      " |-- video_release_date: string (nullable = true)\n",
      " |-- IMDb_url: string (nullable = true)\n",
      " |-- unknown: integer (nullable = true)\n",
      " |-- action: integer (nullable = true)\n",
      " |-- adventure: integer (nullable = true)\n",
      " |-- animation: integer (nullable = true)\n",
      " |-- children\\s: integer (nullable = true)\n",
      " |-- comedy: integer (nullable = true)\n",
      " |-- crime: integer (nullable = true)\n",
      " |-- documentary: integer (nullable = true)\n",
      " |-- drama: integer (nullable = true)\n",
      " |-- fantasy: integer (nullable = true)\n",
      " |-- film-noir: integer (nullable = true)\n",
      " |-- horror: integer (nullable = true)\n",
      " |-- musical: integer (nullable = true)\n",
      " |-- mystery: integer (nullable = true)\n",
      " |-- romance: integer (nullable = true)\n",
      " |-- sci-fi: integer (nullable = true)\n",
      " |-- thriller: integer (nullable = true)\n",
      " |-- war: integer (nullable = true)\n",
      " |-- western: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_items.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as func\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df_ratings.join(df_items, df_items[\"movie_id\"] == df_ratings[\"item_id\"]).groupby(df_ratings[\"user_id\"]).agg(func.sum(func.when(df_items[\"action\"] == 1, df_ratings[\"user_id\"])).alias(\"action\"),\n",
    "                                        func.sum(func.when(df_items[\"adventure\"] == 1, df_ratings[\"user_id\"])).alias(\"adv\"),\n",
    "                                        func.sum(func.when(df_items[\"animation\"] == 1, df_ratings[\"user_id\"])).alias(\"anim\")\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+-----+----+\n",
      "|user_id|action|  adv|anim|\n",
      "+-------+------+-----+----+\n",
      "|    148|  1776| 2220|2072|\n",
      "|    463|  9723| 6945|2315|\n",
      "|    471|  1413| 3297|7536|\n",
      "|    496| 15872|11904|3968|\n",
      "|    833| 59976|24990|2499|\n",
      "|    243|  1458|  972| 243|\n",
      "|    392|  7840| 4704|1960|\n",
      "|    540| 10260| 4320|2700|\n",
      "|    623|  8722| 3738|null|\n",
      "|    737|  5896| 2211|1474|\n",
      "|    858|  5148| 1716|null|\n",
      "|    897| 51129|31395|9867|\n",
      "|     31|   155|   93|null|\n",
      "|    516|  2580| 1548| 516|\n",
      "|    251|  7781| 4267| 753|\n",
      "|     85|  3910| 2720| 850|\n",
      "|    137|  3836| 1918| 137|\n",
      "|    451|  7667| 3157| 451|\n",
      "|    580| 12760| 6380| 580|\n",
      "|    808|  4848|  808|null|\n",
      "+-------+------+-----+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_final.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(\n",
    "    inputCols=[\"action\", \"adv\", \"anim\"],\n",
    "    outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.evaluation import ClusteringEvaluator\n",
    "\n",
    "# Trains a k-means model.\n",
    "kmeans = KMeans().setK(2).setSeed(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "#union a mettre dans la pipeline puis fit le kmeans\n",
    "pipeline = Pipeline(stages=[assembler.setHandleInvalid(\"skip\"), kmeans])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pipeline.fit(df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "euclidean distance = 0.8330579029847824\n"
     ]
    }
   ],
   "source": [
    "predictions = model.transform(df_final)\n",
    "\n",
    "# Evaluate clustering by computing Silhouette score\n",
    "evaluator = ClusteringEvaluator()\n",
    "\n",
    "silhouette = evaluator.evaluate(predictions)\n",
    "print(\"euclidean distance = \" + str(silhouette))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+\n",
      "|user_id|prediction|\n",
      "+-------+----------+\n",
      "|     23|         0|\n",
      "+-------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.select(predictions[\"user_id\"], predictions[\"prediction\"]).where(predictions[\"user_id\"] == 23).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+\n",
      "|user_id|prediction|\n",
      "+-------+----------+\n",
      "|     49|         0|\n",
      "+-------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.select(predictions[\"user_id\"], predictions[\"prediction\"]).where(predictions[\"user_id\"] == 49).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Examen - sujet",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
